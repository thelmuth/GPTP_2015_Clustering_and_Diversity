%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title*{Impact of Lexicase Selection on Diversity and Population Clustering In Genetic Programming}
\titlerunning{Impact of Lexicase Selection on Diversity and Clustering in GP}
% Use \titlerunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\author{Thomas Helmuth, Nicholas Freitag McPhee, Lee Spector}
% Use \authorrunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\institute{Thomas Helmuth \at Computer Science, University of Massachusetts, Amherst, MA USA
\and Nicholas Freitag McPhee \at Division of Science and Mathematics, University of Minnesota, Morris, MN USA
\and Lee Spector \at Cognitive Science, Hampshire College, Amherst, MA USA}

\maketitle

\abstract{Each chapter should be preceded by an abstract (10--15 lines long) that summarizes the content. The abstract will appear \textit{online} at \url{www.SpringerLink.com} and be available with unrestricted access. This allows unregistered users to read the abstract as a teaser for the complete chapter. As a general rule the abstracts will not appear in the printed version of your book unless it is the style of your particular book or that of the series to which your book belongs.}

\begin{keywords}
keywords to your chapter, these words should also be indexed
\end{keywords}
\index{keywords to your chapter}
\index{these words should also be indexed}




\section{Introduction} \label{intro}

\marginpar{Need to get the GECCO 2015 details right in ``spector.bib''.}
Lexicase is a relatively new selection mechanism that has been shown to be effective in a variety of
settings (\cite{Helmuth:2015:ieeeTEC,Helmuth:2015:GECCO}), with significantly higher success rates
than both tournament selection and fitness sharing (IFS).

Outline for intro:

\begin{itemize}
\item parent selection, including lexicase, tourney, and IFS

\item Measures of population structure, including diversity and clustering

\item Source of problems (software benchmarks)

\end{itemize}


\section{Lexicase}

\marginpar{(include description, brief account of prior work, and important properties)}
	
Pseudocode for the lexicase selection algorithm is outlined in 
Algorithm~\ref{alg:lexicase}. In each parent selection event, the lexicase selection algorithm 
first randomly orders the test cases. It then eliminates any individuals in the population 
that do not have the best performance on the first test case. 
Assuming that more than one individual remains, it then loops, eliminating any individuals from 
the remaining candidates that do not have the best performance on the second test case. This 
process continues until only one individual remains and is selected, or until all test cases 
have been used, in which case it randomly selects one of the remaining individuals.

\begin{algorithm}[tb]
	\begin{algorithmic}
		\STATE \texttt{candidates} $:=$ the entire population
		\STATE \texttt{cases} $:=$ list of all the test cases in a random order
		\WHILE{$|\texttt{candidates}|>1$ \AND $|\texttt{cases}|>0$}
			\STATE \texttt{current}, \texttt{cases} := $\textrm{first}(\texttt{cases})$, $\textrm{rest}(\texttt{cases})$
			\STATE \texttt{best\_performance} $:= \min \{ \textrm{perf}(i, \texttt{current}) \;|\; i \in \texttt{candidates} \}$
			\STATE \texttt{candidates} := $\{ i \;|\; i \in \texttt{candidates} \;\land\; \textrm{perf}(i, \texttt{current}) = \texttt{best\_performance}\}$
		\ENDWHILE
		\RETURN random individual from \texttt{candidates}
	\end{algorithmic}
	\caption{Psuedocode for the lexicase selection algorithm. The use of $\min$ when computing 
		\texttt{best\_performance} assumes that the goal is to minimize on each test case, which
		is true in the work presented here, where the goal for all test cases is to minimize error.
		This can be easily generalized to other settings.}
	\label{alg:lexicase}
\end{algorithm}

The central properties of lexicase selection are that (a) it doesn't combine all the errors into a single
fitness value and (b) because of the random ordering of test cases, every test case is likely to be
most important (first to be considered) at least occasionally. With a population of 1,000 individuals
and a problem with 200 test cases, for example, we would expect each test case to be first several
times in each generation. The hope, then, is that this ensures some diversity in the population, with
different (groups of) individuals being rewarded for their ability to perform well on different test
cases.


\section{Explorations of Population Dynamics}

\marginpar{why do we want to explore these things}

The key goal of this paper is to try to better understand why lexicase outperforms tournament selection
and IFS on a variety of problems. One hypothesis is that lexicase helps maintain population diversity
by randomizing the priority of test cases at each selection event, ensuring for example that each test 
case is the most important several times each generation. Here we test this hypothesis by measuring 
diversity in two different ways, error diversity and population clustering, and compare the results 
for lexicase, tournament selection, and IFS.

\subsection{Error Diversity}
\label{sec:errorDiversityDef}

\textit{Error diversity} measures the semantic diversity of a population as the percent of distinct error vectors in the population. When evaluating a program, it is tested on a set of test cases composed of input/output pairs. Then, one or more error functions are applied to the desired output and the programs output, creating an error vector for each individual.

Error diversity is very similar to \textit{behavioral diversity}, which calculates the percent of distinct behavior vectors in the population \citep{Jackson:2010:PPSN}. Here, the behavior of a program is the vector of outputs a program produces when run on the vector of inputs. Error diversity for a population will be less than or equal to its behavioral diversity, since two different behavior vectors may produce the same error vector, but two different error vectors must come from different behavior vectors.

\cite{Helmuth:2015:ieeeTEC} showed that in sets of runs where lexicase achieved higher success rates, 
it also maintained higher population diversity. Here, we would like to explore whether similar 
effects are seen in error diversity across other problems.

\subsection{Population Clustering}
\label{sec:clusterCountDef}

One hypothesis we have developed as to why lexicase selection has led to improved performance compared to tournament selection and IFS is that it enables a population to develop niches of individuals in the population that evolve side-by-side, similar to more explicit niching methods such as island models. These niches would specialize in solving specific subsets of the training set. We expect that evolution may sometimes progress when individuals from separate niches mate, creating children that combine the abilities of each parent and creating a larger niche that combines the parents' niches. If crossover continues combining niches throughout evolution, we hope that eventually an individual will be created that combines the requirements of all of the training cases, solving the problem.

We would like to explore the effects of different parent selection methods on the development of niches within a population. We expect that using lexicase selection will result in larger numbers of clusters than tournament selection or IFS.

To explore the idea of niches within a single population, we must be able to measure the niching of a 
population with respect to the training cases. Our approach here is to use a clustering algorithm to find 
the number of clusters that exist in a population, plotting a measurement of the clustering at each 
generation.

We would like to cluster individuals based on their error vectors across the training cases. 
Since we are primarily interested on whether an individual performs at least as well as every other 
individual in the population, we convert the error vectors into binary ``elitized'' error vectors 
that indicate whether an individual achieved the best error on each test case in that generation. 
This allows us to ignore the differences between individuals that perform poorly on cases in different 
ways, and concentrate on how individuals cluster based on which cases they perform well on.
\marginpar{Does this description of how we ``elitize'' the error vectors make sense? Should we 
	include an example?}

In this work we use agglomerative clustering to count how many clusters there are in the population 
at each generation. Agglomerative clustering creates 
a hierarchical clustering model by first placing each individual into its own cluster. It then 
iteratively combines the two closest clusters into a single cluster, until all clusters have been 
combined into a single cluster. This single cluster includes the distance between each pair of clusters 
that were combined into a larger cluster, and we can break the single cluster into smaller clusters by
``cutting'' the merge between any two clusters whose distance exceeds some threshold.
\marginpar{Should we include a dendogram and talk about the cutting in terms of levels in the diagram?}

Since we are using binary error vectors, we can use the 
Manhattan distance as our distance metric, which makes the distance between two error vectors
a count of how many test cases on which those two individuals have different ``eliteness'' 
results.\footnote{We used the \texttt{agnes} \citep{cluster} implementation of 
	agglomerative clustering in R \citep{R}, using the \texttt{average} linkage when 
	combining clusters.} 
We chose to count the number of clusters that differed on at least 10\% of the training cases; 
for example, if a problem has 200 training cases, we counted the number of clusters that differed 
in binary elitness on at least 20 training cases. While this distance is somewhat arbitrary, 
it gives a reasonable and consistent estimate of how many groups of individuals are doing 
significantly different things in a given generation.

\section{Experimental setup}
\label{sec:setup}

To better understand the impact of lexicase selection on population diversity, we collected data
from 100 runs each of 8 different problems described in \cite{Helmuth:2015:GECCO}, all of which are
basic programming problems taken from introductory programming texts. Table~\ref{tab:problems} lists
the problems, a brief description, and the number of test cases; other details of the runs can be
found in \cite{Helmuth:2015:GECCO}. In Table~\ref{tab:successCounts} we've also provided the number 
of successes, i.e., runs where an program was evolved with total error of 0 across all the test cases.
Success rates aren't the focus of this paper, but those numbers give a sense of the relative
difficulty of the problems and illustrate the substantial improvements that lexicase selection
provides over both tournament selection and IFS.

\begin{table}
	\caption{Short descriptions of the 8 test problems used here, along with the number of test cases
		for each. See \cite{Helmuth:2015:GECCO} for more details on each problem.}
	\label{tab:problems}
	\begin{tabular}{lp{6.5cm}r}
		Problem name \quad & Description \quad & \# test cases \\
		\hline
		replace-space-with-newline & Print the input string, replacing spaces with newlines. Also, return the number of non-whitespace characters. & 200 \\
		syllables & Count the number of occurrences of vowels (a, e, i, o, u, y) in the given string and print that number as \texttt{X} in \texttt{The number of syllables is X}. & 100 \\
		string-lengths-backwards & Given a vector of strings, print the length of each string in reverse order (starting with last and ending with first). & 100 \\
		negative-to-zero & Given a vector of integers, return the vector where all negative integers have been replaced by 0. & 200 \\
		double-letters & Given a string, print the string, doubling every letter character, and tripling every exclamation point. All other non-alphabetic and non-exclamation characters should be printed a single time each. & 100 \\
		scrabble-score & Given a string of visible ASCII characters, return the Scrabble score for that string. & 200 \\
		checksum & Given a string, compute the integer ASCII values of the characters in the string, sum them, take the sum modulo 64, add the integer value of the space character, and then convert that integer back into its corresponding character (the checksum character). The program must print \texttt{Check sum is X}, where \texttt{X} is replaced by the correct checksum character. & 100 \\
		count-odds & Return the number of integers in a given vector that are odd. & 200
	\end{tabular}
\end{table}

\begin{table}
	\caption{Number of successes (out of 100 runs) for each of the 8 test problems used here for each
		tested selection mechanism. These numbers are similar but not identical to those reported in 
		\cite{Helmuth:2015:GECCO} because new runs were performed for this paper.}
	\label{tab:successCounts}
	\begin{tabular}{lrrr}
		Problem name \quad & \# lexicase successes \quad & \# tournament successes \quad & \# IFS successes \\
		\hline
		replace-space-with-newline & 55 & 13 & 17 \\
		syllables & 22 & 1 & 2 \\
		string-lengths-backwards & 75 & 19 & 10 \\
		negative-to-zero & 57 & 15 & 7 \\
		double-letters & 5 & 0 & 0 \\
		scrabble-score & 0 & 0 & 0 \\
		checksum & 0 & 0 & 0 \\
		count-odds & 3 & 0 & 0 \\
	\end{tabular}
\end{table}

All runs were done using the Clojush implementation\footnote{\url{https://github.com/lspector/Clojush}} 
of the PushGP system \citep{spector:2002:GPEM, 1068292}. Each run used a population size of 1,000 
individuals, and runs continued for either 300 generations or a until solution was found, whichever 
came first. 

For each run we collected vectors of the test case errors for each individual for every
generation. These were then used to computer the error diversity (see Section~\ref{sec:errorDiversityDef}
above) and the number of clusters (see Section~\ref{sec:clusterCountDef}).

\section{Results}
\label{sec:results}

In this section we present plots showing error diversity and cluster counts over time for each of
the eight test problems. Below each plot is a smaller sub-plot showing the number of successes 
over time for each selection; since runs end when a solution is found, the successes plot gives a
sense of how many runs are still being represented in primary plot at a given number of generations.
In Figure~\ref{rswnDiv}, for example, the number of lexicase successes is nearly 25 by generation
50, and nearly 50 by generation 150. Thus there are slightly more than 75 data points still represented
in the lexicase data at generation 50, but only about 50 data points represented from generations 150
to 300. Each plot includes a line indicating the median error diversity or median cluster count across
whichever of the 100 runs was still running at that generation; the lexicase line is marked with circles,
the tournament selection line with triangles, and the IFS line with squares. We also indicate the 
range from the 25\% percentile to the 75\% percentile with a gray band around the median line; 
unfortunately the tournament and IFS results are often very similar and strongly overlap.\marginpar{We've used transparency
	to try to let you ``see through'' the overlap, but that's still awkward, and it's unclear how
	well that will print when it gets to the book.}

In general the error diversity numbers for lexicase are substantially and significantly
higher than those for either tournament selection or IFS, both of which tend to be extremely similar.
The string-lengths-backwards problems was the only problem for which there was any substantial overlap 
between the range of values for lexicase and the other two selection mechanisms (see 
Figure~\ref{string-lengths-backwardsDiv}). Typically the lexicase error diversity rises very sharply
in the early generations leveling off somewhere between 0.75 and 1.0, meaning that between $3/4$ or
more of the individuals in the lexicase runs have unique ``elitized'' error vectors. This is in contrast
to the tournament selection and IFS results, where the median error diversity values rarely rise above
0.5; the two exceptions are on the scrabble-score and count-odds problems 
(Figures~\ref{scrabble-scoreDiv} and~\ref{count-oddsDiv}), which neither ever
solved, where the error diversity values approach or exceed 0.75.

The cluster count results are more mixed. Lexicase has clearly higher cluster counts for
half of the problems (replace-space-with-newline, syllables, scrabble-score, and count-odds;
Figures~\ref{rswnClu}, \ref{syllablesClu}, \ref{scrabble-scoreClu} and~\ref{count-oddsClu}).
It also starts with much higher counts on the double-letters problem (Figure~\ref{double-lettersClu}), 
but those numbers drop again quickly, matching the other two approaches by around generation 100. 
On the negative-to-zero problem (Figure~\ref{negative-to-zeroClu}), the lexicase
cluster counts remain small (about the same as for both tournament selection and IFS) throughout the runs.
Particularly striking are lexicase cluster counts for string-lengths-backwards and checksum, where the
number of clusters with lexicase are actually lower earlier in the run. The number of clusters with
checksum remain low throughout (Figure~\ref{checksumClu}), while the number of string-lengths-backwards 
clusters climb up to roughly the same values as tournament selection and IFS by around generation 150 
(Figure~\ref{string-lengths-backwardsClu}).

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{replace-space-with-newline-diversity.pdf}
\caption{Replace Space With Newline -- error diversity.}
\label{rswnDiv}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{replace-space-with-newline-cluster.pdf}
\caption{Replace Space With Newline -- clusters.}
\label{rswnClu}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{syllables-diversity.pdf}
\caption{syllables -- error diversity.}
\label{syllablesDiv}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{syllables-cluster.pdf}
\caption{syllables -- clusters.}
\label{syllablesClu}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{string-lengths-backwards-diversity.pdf}
\caption{string-lengths-backwards -- error diversity.}
\label{string-lengths-backwardsDiv}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{string-lengths-backwards-cluster.pdf}
\caption{string-lengths-backwards -- clusters.}
\label{string-lengths-backwardsClu}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{negative-to-zero-diversity.pdf}
\caption{negative-to-zero -- error diversity.}
\label{negative-to-zeroDiv}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{negative-to-zero-cluster.pdf}
\caption{negative-to-zero -- clusters.}
\label{negative-to-zeroClu}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{double-letters-diversity.pdf}
\caption{double-letters -- error diversity.}
\label{double-lettersDiv}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{double-letters-cluster.pdf}
\caption{double-letters -- clusters.}
\label{double-lettersClu}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{scrabble-score-diversity.pdf}
\caption{scrabble-score -- error diversity.}
\label{scrabble-scoreDiv}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{scrabble-score-cluster.pdf}
\caption{scrabble-score -- clusters.}
\label{scrabble-scoreClu}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{checksum-diversity.pdf}
\caption{checksum -- error diversity.}
\label{checksumDiv}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{checksum-cluster.pdf}
\caption{checksum -- clusters.}
\label{checksumClu}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{count-odds-diversity.pdf}
\caption{count-odds -- error diversity.}
\label{count-oddsDiv}
\end{figure}

\begin{figure}[p] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
%\sidecaption[t]
\centering
\includegraphics[width=11.5cm]{count-odds-cluster.pdf}
\caption{count-odds -- clusters.}
\label{count-oddsClu}
\end{figure}


\section{Discussion and importance of findings}
\label{sec:discussion}

As was the case in \cite{Helmuth:2015:GECCO}, lexicase selection had more successes than 
either tournament selection or IFS on any problem where a solution was discovered; no solution
was found for scrabble-score or checksum with this set of runs using any of the tested 
selection mechanisms. The error diversity for the lexicase runs was much higher than for tournament
selection and IFS for almost all eight problems, which is consistent with the hypothesis that
lexicase helps maintain diversity throughout the run. The lexicase error diversity values tended to
plateau at or above 0.75, meaning that in a population of 1,000 individuals there were over 700
\emph{distinct} error vectors. This doesn't ensure that different individuals were \emph{solving}
different test cases; it could just be that many individuals had slightly different incorrect
answers and error values for a few of the test cases. From a search perspective, though, this seems
preferable to having numerous individuals with the same error values, as hopefully those different
error values represent different starting points for subsequent search.

As mentioned in Section~\ref{sec:results}, for four of the eight problems, the cluster counts were
also much higher for lexicase than for the other two selection mechanisms. For some of these problems
(e.g., count-odds) there are over 100 clusters, and for syllables the median cluster count is over 400
from generation 100 forward. This means that there are hundreds of groups of individuals in these runs
whose error vectors are not just distinct, but that their ``elitized'' values differ on at least 10\%
of the test cases. For count-odds, which has 200 test cases, that means there are consistently over
100 clusters, where each pair of clusters has different ``elitized'' values for at least 20 test cases.
This suggests there lexicase is maintaining large numbers of sub-groups of the population that are 
capable of solving different parts of the problem. If solutions aren't being discovered (and they're
not coming quickly) that might indicate that the genetic operators aren't able to act on the structure 
of the programs in those sub-populations in ways that allow progress.

Interpretation of the cluster count results on the other four problems is more difficult. Analysis
of some of the lexicase checksum runs suggests that the lack of clustering there might be a function
of some structural issues with the test cases. For that problem 50 of the 100 test cases are simply
checking that the program prints \texttt{Check sum is} at the start of its printed text, where the other
50 test cases are confirming that the printed check sum character is in fact correct. Looking at run
results, it appears that populations quickly evolve the ability to print \texttt{Check sum is}, but
then stall, with each program essentially producing a different set of random answers to the question
of what the checksum actually is. This allows for fairly high error diversity (over 0.75). This, however,
generates only one or two clusters as any given program tends to only get at most two or three test 
cases right by guessing, meaning that the manhattan distance between any two elitized error vectors
is typically only 5 or 6 at most, putting it well below the 10\% threshold of 10 in this case. This
suggests that a new set of test cases might improve the likelihood of success for the checksum, with
less emphasis on the fairly simple task of printing \texttt{Check sum is} and more single character
input strings so there's a broad group of test cases that only require the basic checksum calculation
on a single character, hopefully providing an initial gradiant that evolution can use to gain
traction on the problem.\marginpar{It seems plausible that further exploration of the other three
	problems with weird clustering results would also be instructive, but we haven't done that yet.}

It's also worth noting that on problems where solutions were discovered, lexicase runs had successes 
all across the 300 generations. This, combined with the high levels of error diversity and the often 
high number of clusters gives one hope that meaningful search was in fact still happening, and that 
those runs were not hopelessly stalled. The plots of successes over time under the primary plots
typically appear to still have positive slope at generation 300, so it would be interesting to
extend these runs to 500 or 1,000 generations and see how many additional solutions are discovered.
If lexicase is indeed maintaining a meaningful pool of diversity, we would expect to see solutions continue
to be discovered, and at a higher rate than for either tournament selection or IFS. This might be
particularly interesting for problems where solution discovery is rare but possible, such as
double-letters and count-odds, which are solved using lexicase 5 and 3 times respectively, but not
at all using tournament selection and IFS. Solutions for these two problems tended to be discovered
later in the run (double-letters: 109, 122, 192, 275, and 291; count-odds: 65, 233, 279), so letting
runs on those problems go longer might be revealing.

\marginpar{Tournament and IFS seem to be super similar. What, if anything, do we say about that?}

\section{Conclusions}

In short:
\begin{itemize}
	\item Lexicase selection does appear to increase and maintain population diversity.
	\item Error diversity is consistently higher, usually \emph{much} higher with lexicase than
	with either tournament selection or IFS.
	\item Cluster counts are typically higher for lexicase, and when they aren't that may be
	indicating important things about the problem or test case structure.
	\item Lexicase runs continue to find solutions all through the 300 generations, suggesting
	that the diversity is often able to be leveraged.
\end{itemize}

\begin{acknowledgement}
Added later.
\end{acknowledgement}

\bibliographystyle{spbasic}
\bibliography{gp-bibliography,spector}
